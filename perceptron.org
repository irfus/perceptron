* Single Cell Perceptron in Python: Implementation and Results
** Data
In this section, we describe the data we will use for training and testing the performance of our perceptron classifier. We will be using five datasets to test the model. The first three are the truth tables generated by the boolean functions 'AND', 'OR', and 'XOR' on three input variables. We expect our model to learn the 'AND' and 'OR' functions, but not 'XOR'.

The final two datasets are derived from the Iris flower dataset. The original dataset has three output classes, one of which is linearly separable from the other two, and one is not. On this basis, the dataset is divided into two derived sets with binary class outputs, corresponding to the linear and non-linear variables respectively.

#+name: and-data
| 0 | 0 | 0 | 0 |
| 0 | 0 | 1 | 0 |
| 0 | 1 | 0 | 0 |
| 0 | 1 | 1 | 0 |
| 1 | 0 | 0 | 0 |
| 1 | 0 | 1 | 0 |
| 1 | 1 | 0 | 0 |
| 1 | 1 | 1 | 1 |


#+name: or-data
| 0 | 0 | 0 | 0 |
| 0 | 0 | 1 | 1 |
| 0 | 1 | 0 | 1 |
| 0 | 1 | 1 | 1 |
| 1 | 0 | 0 | 1 |
| 1 | 0 | 1 | 1 |
| 1 | 1 | 0 | 1 |
| 1 | 1 | 1 | 1 |

#+name: xor-data
| 0 | 0 | 0 | 0 |
| 0 | 0 | 1 | 1 |
| 0 | 1 | 0 | 1 |
| 0 | 1 | 1 | 0 |
| 1 | 0 | 0 | 1 |
| 1 | 0 | 1 | 0 |
| 1 | 1 | 0 | 0 |
| 1 | 1 | 1 | 0 |

#+name: iris-data-linear
#+BEGIN_SRC python :results value table org drawer
with open("iris.csv") as f:
    data = f.read().split('\n')
    data = [row.split(',') for row in data]
for row in data:
    if row[-1] == "Iris-setosa":
        row[-1] = '1'
    else:
        row[-1] = '0'
    # print("|", "|".join(row), "|")
return data
#+END_SRC

#+RESULTS: iris-data-linear
:RESULTS:
| 5.1 | 3.5 | 1.4 | 0.2 | 1 |
| 4.9 | 3.0 | 1.4 | 0.2 | 1 |
| 4.7 | 3.2 | 1.3 | 0.2 | 1 |
| 4.6 | 3.1 | 1.5 | 0.2 | 1 |
| 5.0 | 3.6 | 1.4 | 0.2 | 1 |
| 5.4 | 3.9 | 1.7 | 0.4 | 1 |
| 4.6 | 3.4 | 1.4 | 0.3 | 1 |
| 5.0 | 3.4 | 1.5 | 0.2 | 1 |
| 4.4 | 2.9 | 1.4 | 0.2 | 1 |
| 4.9 | 3.1 | 1.5 | 0.1 | 1 |
| 5.4 | 3.7 | 1.5 | 0.2 | 1 |
| 4.8 | 3.4 | 1.6 | 0.2 | 1 |
| 4.8 | 3.0 | 1.4 | 0.1 | 1 |
| 4.3 | 3.0 | 1.1 | 0.1 | 1 |
| 5.8 | 4.0 | 1.2 | 0.2 | 1 |
| 5.7 | 4.4 | 1.5 | 0.4 | 1 |
| 5.4 | 3.9 | 1.3 | 0.4 | 1 |
| 5.1 | 3.5 | 1.4 | 0.3 | 1 |
| 5.7 | 3.8 | 1.7 | 0.3 | 1 |
| 5.1 | 3.8 | 1.5 | 0.3 | 1 |
| 5.4 | 3.4 | 1.7 | 0.2 | 1 |
| 5.1 | 3.7 | 1.5 | 0.4 | 1 |
| 4.6 | 3.6 | 1.0 | 0.2 | 1 |
| 5.1 | 3.3 | 1.7 | 0.5 | 1 |
| 4.8 | 3.4 | 1.9 | 0.2 | 1 |
| 5.0 | 3.0 | 1.6 | 0.2 | 1 |
| 5.0 | 3.4 | 1.6 | 0.4 | 1 |
| 5.2 | 3.5 | 1.5 | 0.2 | 1 |
| 5.2 | 3.4 | 1.4 | 0.2 | 1 |
| 4.7 | 3.2 | 1.6 | 0.2 | 1 |
| 4.8 | 3.1 | 1.6 | 0.2 | 1 |
| 5.4 | 3.4 | 1.5 | 0.4 | 1 |
| 5.2 | 4.1 | 1.5 | 0.1 | 1 |
| 5.5 | 4.2 | 1.4 | 0.2 | 1 |
| 4.9 | 3.1 | 1.5 | 0.1 | 1 |
| 5.0 | 3.2 | 1.2 | 0.2 | 1 |
| 5.5 | 3.5 | 1.3 | 0.2 | 1 |
| 4.9 | 3.1 | 1.5 | 0.1 | 1 |
| 4.4 | 3.0 | 1.3 | 0.2 | 1 |
| 5.1 | 3.4 | 1.5 | 0.2 | 1 |
| 5.0 | 3.5 | 1.3 | 0.3 | 1 |
| 4.5 | 2.3 | 1.3 | 0.3 | 1 |
| 4.4 | 3.2 | 1.3 | 0.2 | 1 |
| 5.0 | 3.5 | 1.6 | 0.6 | 1 |
| 5.1 | 3.8 | 1.9 | 0.4 | 1 |
| 4.8 | 3.0 | 1.4 | 0.3 | 1 |
| 5.1 | 3.8 | 1.6 | 0.2 | 1 |
| 4.6 | 3.2 | 1.4 | 0.2 | 1 |
| 5.3 | 3.7 | 1.5 | 0.2 | 1 |
| 5.0 | 3.3 | 1.4 | 0.2 | 1 |
| 7.0 | 3.2 | 4.7 | 1.4 | 0 |
| 6.4 | 3.2 | 4.5 | 1.5 | 0 |
| 6.9 | 3.1 | 4.9 | 1.5 | 0 |
| 5.5 | 2.3 | 4.0 | 1.3 | 0 |
| 6.5 | 2.8 | 4.6 | 1.5 | 0 |
| 5.7 | 2.8 | 4.5 | 1.3 | 0 |
| 6.3 | 3.3 | 4.7 | 1.6 | 0 |
| 4.9 | 2.4 | 3.3 | 1.0 | 0 |
| 6.6 | 2.9 | 4.6 | 1.3 | 0 |
| 5.2 | 2.7 | 3.9 | 1.4 | 0 |
| 5.0 | 2.0 | 3.5 | 1.0 | 0 |
| 5.9 | 3.0 | 4.2 | 1.5 | 0 |
| 6.0 | 2.2 | 4.0 | 1.0 | 0 |
| 6.1 | 2.9 | 4.7 | 1.4 | 0 |
| 5.6 | 2.9 | 3.6 | 1.3 | 0 |
| 6.7 | 3.1 | 4.4 | 1.4 | 0 |
| 5.6 | 3.0 | 4.5 | 1.5 | 0 |
| 5.8 | 2.7 | 4.1 | 1.0 | 0 |
| 6.2 | 2.2 | 4.5 | 1.5 | 0 |
| 5.6 | 2.5 | 3.9 | 1.1 | 0 |
| 5.9 | 3.2 | 4.8 | 1.8 | 0 |
| 6.1 | 2.8 | 4.0 | 1.3 | 0 |
| 6.3 | 2.5 | 4.9 | 1.5 | 0 |
| 6.1 | 2.8 | 4.7 | 1.2 | 0 |
| 6.4 | 2.9 | 4.3 | 1.3 | 0 |
| 6.6 | 3.0 | 4.4 | 1.4 | 0 |
| 6.8 | 2.8 | 4.8 | 1.4 | 0 |
| 6.7 | 3.0 | 5.0 | 1.7 | 0 |
| 6.0 | 2.9 | 4.5 | 1.5 | 0 |
| 5.7 | 2.6 | 3.5 | 1.0 | 0 |
| 5.5 | 2.4 | 3.8 | 1.1 | 0 |
| 5.5 | 2.4 | 3.7 | 1.0 | 0 |
| 5.8 | 2.7 | 3.9 | 1.2 | 0 |
| 6.0 | 2.7 | 5.1 | 1.6 | 0 |
| 5.4 | 3.0 | 4.5 | 1.5 | 0 |
| 6.0 | 3.4 | 4.5 | 1.6 | 0 |
| 6.7 | 3.1 | 4.7 | 1.5 | 0 |
| 6.3 | 2.3 | 4.4 | 1.3 | 0 |
| 5.6 | 3.0 | 4.1 | 1.3 | 0 |
| 5.5 | 2.5 | 4.0 | 1.3 | 0 |
| 5.5 | 2.6 | 4.4 | 1.2 | 0 |
| 6.1 | 3.0 | 4.6 | 1.4 | 0 |
| 5.8 | 2.6 | 4.0 | 1.2 | 0 |
| 5.0 | 2.3 | 3.3 | 1.0 | 0 |
| 5.6 | 2.7 | 4.2 | 1.3 | 0 |
| 5.7 | 3.0 | 4.2 | 1.2 | 0 |
| 5.7 | 2.9 | 4.2 | 1.3 | 0 |
| 6.2 | 2.9 | 4.3 | 1.3 | 0 |
| 5.1 | 2.5 | 3.0 | 1.1 | 0 |
| 5.7 | 2.8 | 4.1 | 1.3 | 0 |
| 6.3 | 3.3 | 6.0 | 2.5 | 0 |
| 5.8 | 2.7 | 5.1 | 1.9 | 0 |
| 7.1 | 3.0 | 5.9 | 2.1 | 0 |
| 6.3 | 2.9 | 5.6 | 1.8 | 0 |
| 6.5 | 3.0 | 5.8 | 2.2 | 0 |
| 7.6 | 3.0 | 6.6 | 2.1 | 0 |
| 4.9 | 2.5 | 4.5 | 1.7 | 0 |
| 7.3 | 2.9 | 6.3 | 1.8 | 0 |
| 6.7 | 2.5 | 5.8 | 1.8 | 0 |
| 7.2 | 3.6 | 6.1 | 2.5 | 0 |
| 6.5 | 3.2 | 5.1 | 2.0 | 0 |
| 6.4 | 2.7 | 5.3 | 1.9 | 0 |
| 6.8 | 3.0 | 5.5 | 2.1 | 0 |
| 5.7 | 2.5 | 5.0 | 2.0 | 0 |
| 5.8 | 2.8 | 5.1 | 2.4 | 0 |
| 6.4 | 3.2 | 5.3 | 2.3 | 0 |
| 6.5 | 3.0 | 5.5 | 1.8 | 0 |
| 7.7 | 3.8 | 6.7 | 2.2 | 0 |
| 7.7 | 2.6 | 6.9 | 2.3 | 0 |
| 6.0 | 2.2 | 5.0 | 1.5 | 0 |
| 6.9 | 3.2 | 5.7 | 2.3 | 0 |
| 5.6 | 2.8 | 4.9 | 2.0 | 0 |
| 7.7 | 2.8 | 6.7 | 2.0 | 0 |
| 6.3 | 2.7 | 4.9 | 1.8 | 0 |
| 6.7 | 3.3 | 5.7 | 2.1 | 0 |
| 7.2 | 3.2 | 6.0 | 1.8 | 0 |
| 6.2 | 2.8 | 4.8 | 1.8 | 0 |
| 6.1 | 3.0 | 4.9 | 1.8 | 0 |
| 6.4 | 2.8 | 5.6 | 2.1 | 0 |
| 7.2 | 3.0 | 5.8 | 1.6 | 0 |
| 7.4 | 2.8 | 6.1 | 1.9 | 0 |
| 7.9 | 3.8 | 6.4 | 2.0 | 0 |
| 6.4 | 2.8 | 5.6 | 2.2 | 0 |
| 6.3 | 2.8 | 5.1 | 1.5 | 0 |
| 6.1 | 2.6 | 5.6 | 1.4 | 0 |
| 7.7 | 3.0 | 6.1 | 2.3 | 0 |
| 6.3 | 3.4 | 5.6 | 2.4 | 0 |
| 6.4 | 3.1 | 5.5 | 1.8 | 0 |
| 6.0 | 3.0 | 4.8 | 1.8 | 0 |
| 6.9 | 3.1 | 5.4 | 2.1 | 0 |
| 6.7 | 3.1 | 5.6 | 2.4 | 0 |
| 6.9 | 3.1 | 5.1 | 2.3 | 0 |
| 5.8 | 2.7 | 5.1 | 1.9 | 0 |
| 6.8 | 3.2 | 5.9 | 2.3 | 0 |
| 6.7 | 3.3 | 5.7 | 2.5 | 0 |
| 6.7 | 3.0 | 5.2 | 2.3 | 0 |
| 6.3 | 2.5 | 5.0 | 1.9 | 0 |
| 6.5 | 3.0 | 5.2 | 2.0 | 0 |
| 6.2 | 3.4 | 5.4 | 2.3 | 0 |
| 5.9 | 3.0 | 5.1 | 1.8 | 0 |
:END:

#+name: iris-data-nonlinear
#+BEGIN_SRC python :results value table org drawer
with open("iris.csv") as f:
    data = f.read().split('\n')
    data = [row.split(',') for row in data]
for row in data:
    if row[-1] == "Iris-virginica":
        row[-1] = '1'
    else:
        row[-1] = '0'
#     print("|", "|".join(row), "|")
return data
#+END_SRC

#+RESULTS: iris-data-nonlinear
:RESULTS:
| 5.1 | 3.5 | 1.4 | 0.2 | 0 |
| 4.9 | 3.0 | 1.4 | 0.2 | 0 |
| 4.7 | 3.2 | 1.3 | 0.2 | 0 |
| 4.6 | 3.1 | 1.5 | 0.2 | 0 |
| 5.0 | 3.6 | 1.4 | 0.2 | 0 |
| 5.4 | 3.9 | 1.7 | 0.4 | 0 |
| 4.6 | 3.4 | 1.4 | 0.3 | 0 |
| 5.0 | 3.4 | 1.5 | 0.2 | 0 |
| 4.4 | 2.9 | 1.4 | 0.2 | 0 |
| 4.9 | 3.1 | 1.5 | 0.1 | 0 |
| 5.4 | 3.7 | 1.5 | 0.2 | 0 |
| 4.8 | 3.4 | 1.6 | 0.2 | 0 |
| 4.8 | 3.0 | 1.4 | 0.1 | 0 |
| 4.3 | 3.0 | 1.1 | 0.1 | 0 |
| 5.8 | 4.0 | 1.2 | 0.2 | 0 |
| 5.7 | 4.4 | 1.5 | 0.4 | 0 |
| 5.4 | 3.9 | 1.3 | 0.4 | 0 |
| 5.1 | 3.5 | 1.4 | 0.3 | 0 |
| 5.7 | 3.8 | 1.7 | 0.3 | 0 |
| 5.1 | 3.8 | 1.5 | 0.3 | 0 |
| 5.4 | 3.4 | 1.7 | 0.2 | 0 |
| 5.1 | 3.7 | 1.5 | 0.4 | 0 |
| 4.6 | 3.6 | 1.0 | 0.2 | 0 |
| 5.1 | 3.3 | 1.7 | 0.5 | 0 |
| 4.8 | 3.4 | 1.9 | 0.2 | 0 |
| 5.0 | 3.0 | 1.6 | 0.2 | 0 |
| 5.0 | 3.4 | 1.6 | 0.4 | 0 |
| 5.2 | 3.5 | 1.5 | 0.2 | 0 |
| 5.2 | 3.4 | 1.4 | 0.2 | 0 |
| 4.7 | 3.2 | 1.6 | 0.2 | 0 |
| 4.8 | 3.1 | 1.6 | 0.2 | 0 |
| 5.4 | 3.4 | 1.5 | 0.4 | 0 |
| 5.2 | 4.1 | 1.5 | 0.1 | 0 |
| 5.5 | 4.2 | 1.4 | 0.2 | 0 |
| 4.9 | 3.1 | 1.5 | 0.1 | 0 |
| 5.0 | 3.2 | 1.2 | 0.2 | 0 |
| 5.5 | 3.5 | 1.3 | 0.2 | 0 |
| 4.9 | 3.1 | 1.5 | 0.1 | 0 |
| 4.4 | 3.0 | 1.3 | 0.2 | 0 |
| 5.1 | 3.4 | 1.5 | 0.2 | 0 |
| 5.0 | 3.5 | 1.3 | 0.3 | 0 |
| 4.5 | 2.3 | 1.3 | 0.3 | 0 |
| 4.4 | 3.2 | 1.3 | 0.2 | 0 |
| 5.0 | 3.5 | 1.6 | 0.6 | 0 |
| 5.1 | 3.8 | 1.9 | 0.4 | 0 |
| 4.8 | 3.0 | 1.4 | 0.3 | 0 |
| 5.1 | 3.8 | 1.6 | 0.2 | 0 |
| 4.6 | 3.2 | 1.4 | 0.2 | 0 |
| 5.3 | 3.7 | 1.5 | 0.2 | 0 |
| 5.0 | 3.3 | 1.4 | 0.2 | 0 |
| 7.0 | 3.2 | 4.7 | 1.4 | 0 |
| 6.4 | 3.2 | 4.5 | 1.5 | 0 |
| 6.9 | 3.1 | 4.9 | 1.5 | 0 |
| 5.5 | 2.3 | 4.0 | 1.3 | 0 |
| 6.5 | 2.8 | 4.6 | 1.5 | 0 |
| 5.7 | 2.8 | 4.5 | 1.3 | 0 |
| 6.3 | 3.3 | 4.7 | 1.6 | 0 |
| 4.9 | 2.4 | 3.3 | 1.0 | 0 |
| 6.6 | 2.9 | 4.6 | 1.3 | 0 |
| 5.2 | 2.7 | 3.9 | 1.4 | 0 |
| 5.0 | 2.0 | 3.5 | 1.0 | 0 |
| 5.9 | 3.0 | 4.2 | 1.5 | 0 |
| 6.0 | 2.2 | 4.0 | 1.0 | 0 |
| 6.1 | 2.9 | 4.7 | 1.4 | 0 |
| 5.6 | 2.9 | 3.6 | 1.3 | 0 |
| 6.7 | 3.1 | 4.4 | 1.4 | 0 |
| 5.6 | 3.0 | 4.5 | 1.5 | 0 |
| 5.8 | 2.7 | 4.1 | 1.0 | 0 |
| 6.2 | 2.2 | 4.5 | 1.5 | 0 |
| 5.6 | 2.5 | 3.9 | 1.1 | 0 |
| 5.9 | 3.2 | 4.8 | 1.8 | 0 |
| 6.1 | 2.8 | 4.0 | 1.3 | 0 |
| 6.3 | 2.5 | 4.9 | 1.5 | 0 |
| 6.1 | 2.8 | 4.7 | 1.2 | 0 |
| 6.4 | 2.9 | 4.3 | 1.3 | 0 |
| 6.6 | 3.0 | 4.4 | 1.4 | 0 |
| 6.8 | 2.8 | 4.8 | 1.4 | 0 |
| 6.7 | 3.0 | 5.0 | 1.7 | 0 |
| 6.0 | 2.9 | 4.5 | 1.5 | 0 |
| 5.7 | 2.6 | 3.5 | 1.0 | 0 |
| 5.5 | 2.4 | 3.8 | 1.1 | 0 |
| 5.5 | 2.4 | 3.7 | 1.0 | 0 |
| 5.8 | 2.7 | 3.9 | 1.2 | 0 |
| 6.0 | 2.7 | 5.1 | 1.6 | 0 |
| 5.4 | 3.0 | 4.5 | 1.5 | 0 |
| 6.0 | 3.4 | 4.5 | 1.6 | 0 |
| 6.7 | 3.1 | 4.7 | 1.5 | 0 |
| 6.3 | 2.3 | 4.4 | 1.3 | 0 |
| 5.6 | 3.0 | 4.1 | 1.3 | 0 |
| 5.5 | 2.5 | 4.0 | 1.3 | 0 |
| 5.5 | 2.6 | 4.4 | 1.2 | 0 |
| 6.1 | 3.0 | 4.6 | 1.4 | 0 |
| 5.8 | 2.6 | 4.0 | 1.2 | 0 |
| 5.0 | 2.3 | 3.3 | 1.0 | 0 |
| 5.6 | 2.7 | 4.2 | 1.3 | 0 |
| 5.7 | 3.0 | 4.2 | 1.2 | 0 |
| 5.7 | 2.9 | 4.2 | 1.3 | 0 |
| 6.2 | 2.9 | 4.3 | 1.3 | 0 |
| 5.1 | 2.5 | 3.0 | 1.1 | 0 |
| 5.7 | 2.8 | 4.1 | 1.3 | 0 |
| 6.3 | 3.3 | 6.0 | 2.5 | 1 |
| 5.8 | 2.7 | 5.1 | 1.9 | 1 |
| 7.1 | 3.0 | 5.9 | 2.1 | 1 |
| 6.3 | 2.9 | 5.6 | 1.8 | 1 |
| 6.5 | 3.0 | 5.8 | 2.2 | 1 |
| 7.6 | 3.0 | 6.6 | 2.1 | 1 |
| 4.9 | 2.5 | 4.5 | 1.7 | 1 |
| 7.3 | 2.9 | 6.3 | 1.8 | 1 |
| 6.7 | 2.5 | 5.8 | 1.8 | 1 |
| 7.2 | 3.6 | 6.1 | 2.5 | 1 |
| 6.5 | 3.2 | 5.1 | 2.0 | 1 |
| 6.4 | 2.7 | 5.3 | 1.9 | 1 |
| 6.8 | 3.0 | 5.5 | 2.1 | 1 |
| 5.7 | 2.5 | 5.0 | 2.0 | 1 |
| 5.8 | 2.8 | 5.1 | 2.4 | 1 |
| 6.4 | 3.2 | 5.3 | 2.3 | 1 |
| 6.5 | 3.0 | 5.5 | 1.8 | 1 |
| 7.7 | 3.8 | 6.7 | 2.2 | 1 |
| 7.7 | 2.6 | 6.9 | 2.3 | 1 |
| 6.0 | 2.2 | 5.0 | 1.5 | 1 |
| 6.9 | 3.2 | 5.7 | 2.3 | 1 |
| 5.6 | 2.8 | 4.9 | 2.0 | 1 |
| 7.7 | 2.8 | 6.7 | 2.0 | 1 |
| 6.3 | 2.7 | 4.9 | 1.8 | 1 |
| 6.7 | 3.3 | 5.7 | 2.1 | 1 |
| 7.2 | 3.2 | 6.0 | 1.8 | 1 |
| 6.2 | 2.8 | 4.8 | 1.8 | 1 |
| 6.1 | 3.0 | 4.9 | 1.8 | 1 |
| 6.4 | 2.8 | 5.6 | 2.1 | 1 |
| 7.2 | 3.0 | 5.8 | 1.6 | 1 |
| 7.4 | 2.8 | 6.1 | 1.9 | 1 |
| 7.9 | 3.8 | 6.4 | 2.0 | 1 |
| 6.4 | 2.8 | 5.6 | 2.2 | 1 |
| 6.3 | 2.8 | 5.1 | 1.5 | 1 |
| 6.1 | 2.6 | 5.6 | 1.4 | 1 |
| 7.7 | 3.0 | 6.1 | 2.3 | 1 |
| 6.3 | 3.4 | 5.6 | 2.4 | 1 |
| 6.4 | 3.1 | 5.5 | 1.8 | 1 |
| 6.0 | 3.0 | 4.8 | 1.8 | 1 |
| 6.9 | 3.1 | 5.4 | 2.1 | 1 |
| 6.7 | 3.1 | 5.6 | 2.4 | 1 |
| 6.9 | 3.1 | 5.1 | 2.3 | 1 |
| 5.8 | 2.7 | 5.1 | 1.9 | 1 |
| 6.8 | 3.2 | 5.9 | 2.3 | 1 |
| 6.7 | 3.3 | 5.7 | 2.5 | 1 |
| 6.7 | 3.0 | 5.2 | 2.3 | 1 |
| 6.3 | 2.5 | 5.0 | 1.9 | 1 |
| 6.5 | 3.0 | 5.2 | 2.0 | 1 |
| 6.2 | 3.4 | 5.4 | 2.3 | 1 |
| 5.9 | 3.0 | 5.1 | 1.8 | 1 |
:END:

** Model
In the following python block, our class for a perceptron model will be set up. This class is initialised from the data to be modelled. We assume that the passed data is pre-formatted such that the first n-1 columns are the inputs and the column n is a binary output class. The class reads this data, separates inputs and outputs into different data structures, and initialises a randomised array of weights corresponding to the number of input variables. An initial error value is taken to be an impossibly large float.

The class implements a predict method, which takes in a row of inputs and returns a binary output. The predict function can be passed a theta value, which defaults to 1. Print methods are implemented for weights and the stored error value.

#+name: perceptron-class
#+BEGIN_SRC ipython :results silent :tangle perceptron.py
import random
import numpy as np
from sys import maxsize


class Perceptron:
    def __init__(self, data):
        random.shuffle(data)
        inputs = np.array([[float(x) for x in row[0:-1]] for row in data])
        self.inputs = np.hstack((inputs, [[1]] * len(inputs)))
        self.outputs = np.array([float(row[-1]) for row in data])
        self.numInputs = len(self.inputs[0])
        weights = np.array([random.uniform(0, 100) \
                                 for x in range(self.numInputs)])
        weights[-1] = -1.0
        self.weights = weights
        self.error = float(maxsize)
        self.fitHistory = []

    def predict(self, x_i):
        y = np.dot(x_i, self.weights)
        if y >= 0:
            return 1
        else:
            return 0

    def fit(self, print_weights = False, lr=1, numIters = 100):
        errorList = []
        for iter in range(numIters):
            totalError = 0.0
            for i in range(len(self.outputs)):
                pred = self.predict(self.inputs[i])
                error = self.outputs[i] - pred
                self.weights[:-1] = self.weights[:-1] + \
                               lr * error * self.inputs[i][:-1]
                self.weights[-1] = self.weights[-1] - lr * error
                totalError += abs(error)
            errorList.append(totalError)
            if totalError == 0.0:
                break
            # print("iter {} of {}".format(iter, numIters))
        self.fitHistory = errorList
        self.error = totalError
        
            
    def setError(self, e):
        self.error = e

    def printWeights(self):
        print(self.weights)

    def printError(self):
        print(self.error)

    def __str__(self):
        s = "inputs (1 sample): {}\n".format(self.inputs[0])
        s += "weights: {}\n".format(self.weights)
        s += "error: {}\n".format(self.error)
        return s
#+END_SRC

** COMMENT Train
Here we have the training part of the program.



Now we implement the train portion of the program. This code runs a training loop for a given number of iterations. At first run, a Perceptron object is initialised from the passed data. At each iteration of the training loop, the model's current predictions are used to calculate an error value used to update its weights.

#+name: train-perceptron
#+BEGIN_SRC ipython :results output org drawer :var data = iris-data-linear :tangle train.py
import numpy as np
from perceptron import Perceptron
from matplotlib import pyplot as plt

%matplotlib inline

model = Perceptron(data)
print(model, "\n")
model.fit(lr = 1, numIters = 1000)
plt.plot(model.fitHistory)
plt.xlabel("Iterations")
plt.ylabel("Error")

print(model)
#+END_SRC

#+RESULTS: train-perceptron
:RESULTS:
#+BEGIN_EXAMPLE
inputs (1 sample): [7.2 3.  5.8 1.6 1. ]
weights: [42.70592051 82.62408247 47.62398478 71.14617704 -1.        ]
error: 9.223372036854776e+18
 

inputs (1 sample): [7.2 3.  5.8 1.6 1. ]
weights: [-24.39407949  57.42408247 -30.67601522  38.34617704   8.        ]
error: 0.0

#+END_EXAMPLE

[[file:ipython-inline-images/ob-ipython-12456e49751b52922420157d4cdaba4a.png]]
:END:

** Test
